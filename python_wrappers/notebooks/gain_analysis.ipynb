{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "sys.path.insert(0,\"/home/daqtest/Processor/sandpro\")\n",
    "import sandpro\n",
    "import configparser\n",
    "import json\n",
    "import scipy.stats\n",
    "from scipy.optimize import curve_fit\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "sys.path.insert(0,\"../\")\n",
    "import util\n",
    "from run_selection_single_channel import RunInfo\n",
    "from dataclasses import dataclass\n",
    "import WaveformProcessor\n",
    "import FitSPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../run_info_single_channel.csv\", parse_dates=[\"date_time\"],delimiter=\",\",quotechar='\\0')\n",
    "df = pd.read_csv(\"../run_info_single_channel_20240701_2.csv\", parse_dates=[\"date_time\"],delimiter=\",\",quotechar='\"', skipinitialspace=True, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v_dirname = np.vectorize(os.path.dirname)\n",
    "# v_basename = np.vectorize(os.path.basename)\n",
    "# v_basename = np.vectorize(os.path.basename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_name = v_dirname(df.file_path)\n",
    "# bin_name = v_basename(df.file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class run_info_data:\n",
    "    def __init__(self, input: object):\n",
    "        self.import_data(input)\n",
    "    \n",
    "    def import_data(self, df: pd.DataFrame):\n",
    "        for col_name in df.columns:\n",
    "            setattr(self, col_name, df[col_name].to_numpy())\n",
    "            \n",
    "    def import_data(self, dictionary: dict):\n",
    "        for var_name in dictionary.keys():\n",
    "            setattr(self, var_name, np.array(dictionary[var_name]))\n",
    "            \n",
    "    def apply_mask(self, mask, inplace = False):\n",
    "        print(\"before cut: \", len(self.__dict__['file_path']))\n",
    "        new_dict = {}\n",
    "        for i in self.__dict__.keys():\n",
    "            if inplace:\n",
    "                self.__dict__[i] = self.__dict__[i][mask]\n",
    "            else:\n",
    "                new_dict[i] = self.__dict__[i][mask]\n",
    "        \n",
    "        if inplace:   \n",
    "            first = next(iter(self.__dict__.values()))\n",
    "            print(\"after cut: \", len(first))\n",
    "            return\n",
    "        else:\n",
    "            first = next(iter(new_dict.values()))\n",
    "            print(\"after cut: \", len(first))\n",
    "            return run_info_data(new_dict)\n",
    "    \n",
    "    def __len__(self):\n",
    "        # the length of all array should be the same\n",
    "        # so just picked a random one\n",
    "        first = next(iter(self.__dict__.values()))\n",
    "        return len(first)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _re_search(pattern: str, string: str):\n",
    "    return bool(re.search(pattern, string))\n",
    "v_re_search = np.vectorize(_re_search, excluded=[\"pattern\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = run_info_data(df)\n",
    "print(info.__dict__.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = run_info_data(df)\n",
    "print(info.__dict__.keys())\n",
    "\n",
    "mask_run_tag = v_re_search('GXe/gain_calibration', info.run_tag)\n",
    "mask_run_tag_remove_trash = ~v_re_search('trash', info.run_tag)\n",
    "mask_time = (info.date_time > np.datetime64('2024-05-18'))\n",
    "mask_record_length_nan = ~np.isnan(info.record_length_sample)\n",
    "mask_start_index_nan = ~np.isnan(info.start_index)\n",
    "mask_nevents_nan = ~np.isnan(info.number_of_events)\n",
    "\n",
    "# FIXME: mask channel\n",
    "\n",
    "mask = mask_run_tag & mask_run_tag_remove_trash & mask_time & mask_record_length_nan & mask_start_index_nan & mask_nevents_nan\n",
    "\n",
    "# check how much data is removed\n",
    "info.apply_mask(mask, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data type all correct \n",
    "for i in info.__dict__.keys():\n",
    "    print(i, type(info.__dict__[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# config_name = \"_\".join(parts[1:4]) + \".ini\"\n",
    "# spd.threshold_adc = parts[3]\n",
    "# spd.channel = int(parts[2])\n",
    "# spd.timestamp_str = f\"{int(parts[4])}_{int(parts[5].split('.')[0])}\"\n",
    "\n",
    "# spd.datetime_obj = datetime.datetime.strptime(f\"{parts[4]} {parts[5].split('.')[0]}\", '%Y%m%d %H%M%S')\n",
    "\n",
    "# # ignore the channels that in the ignore_channel_list\n",
    "# if spd.channel in self.ignore_channel_list: \n",
    "#     return\n",
    "\n",
    "# # read from meta data file\n",
    "# with open(meta_data, \"r\") as f:\n",
    "#     data_taking_settings = json.load(f)\n",
    "\n",
    "# spd.n_events = int(data_taking_settings[\"number_of_events\"])\n",
    "# spd.bias_voltage = float(data_taking_settings[\"voltage_config\"][\"preamp_1\"]) # assuming all preamp has the same bias voltage; can be easily changed\n",
    "# # bias_voltage_list.append(bias_voltage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.file_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_channels_list = np.unique(info.number_of_channels)\n",
    "record_length_list = np.unique(info.record_length_sample)\n",
    "n_sample_list = np.unique(info.baseline_n_samples)\n",
    "n_sample_avg_ist = np.unique(info.baseline_n_samples_avg)\n",
    "\n",
    "integral_window = (0.3,0.6)\n",
    "\n",
    "for nchs in number_of_channels_list:\n",
    "    for record_length_sample in record_length_list:\n",
    "        for sample_selection in n_sample_list:\n",
    "            for samples_to_average in n_sample_avg_ist:\n",
    "                mask =  (info.number_of_channels == nchs) & (info.record_length_sample == record_length_sample) & (info.baseline_n_samples == sample_selection) & (info.baseline_n_samples_avg == samples_to_average)\n",
    "                # check how much data is removed\n",
    "                _tmp__selection = info.apply_mask(mask)\n",
    "                \n",
    "                process_config = {\"nchs\": nchs,\n",
    "                                \"nsamps\": record_length_sample,\n",
    "                                \"sample_selection\": sample_selection,\n",
    "                                \"samples_to_average\": samples_to_average}\n",
    "                \n",
    "                # dump the config to a json file\n",
    "                with open(\"process_config.json\", \"w\") as f:\n",
    "                    json.dump(process_config, f)  \n",
    "                    \n",
    "                processor= sandpro.processing.rawdata.RawData(config_file = \"process_config.json\",\n",
    "                                                            perchannel=False)\n",
    "                \n",
    "                for i in range(len(_tmp__selection)):\n",
    "                    start_index = _tmp__selection.start_index[i]\n",
    "                    end_index = _tmp__selection.start_index[i] + _tmp__selection.n_processed_events[i]\n",
    "                    \n",
    "                    data = processor.get_rawdata_numpy(n_evts=_tmp__selection.number_of_events[i]-1,\n",
    "                                            file=_tmp__selection.file_path[i],\n",
    "                                            bit_of_daq=14,\n",
    "                                            headersize=4,inversion=False)\n",
    "                    \n",
    "                    wfp = WaveformProcessor.WFProcessor(os.path.dirname(_tmp__selection.file_path[i]), \n",
    "                                                        volt_per_adc=2/2**14)\n",
    "                    wfp.set_data(data[\"data_per_channel\"][start_index:end_index,0], in_adc = False)\n",
    "                    wfp.process_wfs()\n",
    "                    \n",
    "                    areas = wfp.get_area(sum_window=integral_window)\n",
    "                    heights = wfp.get_height(search_window=integral_window)\n",
    "\n",
    "                    data_processed = data[\"data_per_channel\"][start_index:end_index,0,:]\n",
    "                    hist_count,bin_edges = np.histogram(areas,bins=200,range=(-0.1,10))\n",
    "\n",
    "                    spe_fit = FitSPE.FitSPE(hist_count, bin_edges, show_plot=False, save_plot=False)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(info.file_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set the board number and integral window according to the board number (board 0 and 1 have different integral windows)\n",
    "# board_number = 0\n",
    "# local_channel = channel\n",
    "integral_window = (0.3,0.6)\n",
    "# local_channel = channel - 16\n",
    "\n",
    "\n",
    "# data_file_basename = meta_data_basename.replace(\"meta_\", \"\").replace(\".json\", f\"_board_{board_number}.bin\")\n",
    "\n",
    "try:\n",
    "    data = processor.get_rawdata_numpy(n_evts=df.number_of_events-1,\n",
    "                                file=os.path.join(dir_name, bin_name),\n",
    "                                bit_of_daq=14,\n",
    "                                headersize=4,inversion=False)\n",
    "    spd.start_index, spd.end_index = 2000, spd.n_events-1-500 #first 1000 events are noisy\n",
    "    print(f\"analysing events from range: {spd.start_index} to {spd.end_index}\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    data = processor.get_rawdata_numpy(1999,\n",
    "                                file=os.path.join(self.data_folder, data_file_basename),\n",
    "                                bit_of_daq=14,\n",
    "                                headersize=4,inversion=False)\n",
    "\n",
    "wfp = WaveformProcessor.WFProcessor(self.data_folder, volt_per_adc=2/2**14)\n",
    "wfp.set_data(data[\"data_per_channel\"][spd.start_index:spd.end_index,0], in_adc = False)\n",
    "wfp.process_wfs()\n",
    "\n",
    "spd.baseline_std = np.mean(wfp.baseline_rms)\n",
    "spd.baseline_mean = np.mean(wfp.baseline)\n",
    "spd.n_processed_events = len(wfp.baseline_rms)\n",
    "\n",
    "spd.areas = wfp.get_area(sum_window=spd.integral_window)\n",
    "spd.heights = wfp.get_height(search_window=spd.integral_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist2d(df.voltage_preamp1, df.baseline_std, bins=[50,50],range=[[0,100],[0,0.001]], cmap='viridis',norm=\"log\")\n",
    "plt.plot(df.voltage_preamp1, df.baseline_std, 'o')\n",
    "plt.xlabel(\"Voltage Preamp 1 (V)\")\n",
    "plt.ylabel(\"Baseline Std (to be determined)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist2d(df.voltage_preamp1, df.baseline_std, bins=[50,50],range=[[0,100],[0,0.001]], cmap='viridis',norm=\"log\")\n",
    "runtime = df.runtime.to_numpy()\n",
    "baseline = df.baseline_std.to_numpy()\n",
    "\n",
    "    \n",
    "plt.xlabel(\"Runtime of previous file\")\n",
    "plt.ylabel(\"Baseline Std (to be determined)\")\n",
    "\n",
    "# plt.xlim(0,5000)\n",
    "# bins=[200,100],range=[[-0.1,10],[0,60]],\n",
    "plt.hist2d(runtime,baseline,cmap='viridis',norm=\"log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['file_path'] = df['file_path'].astype(str)\n",
    "df['comment'] = df['comment'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df['date_time'], format=\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types of df columns\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 06:56:58) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e020b59b42c8092ceaf990bd8aec4e48e17ae4da9fded5f788d4ff08af955f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
